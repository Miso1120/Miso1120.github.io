---
layout: single
title: "머신러닝4-1(로지스틱 회귀)"
categories: MachineLearning
sidebar:
    nav: "counts"
---
# 로지스틱 회귀

# 럭키백의 확률 구하기

럭키백의 확률 구하기

: 총 7개의 생선이 들어가며 크기, 무게 등이 주어졌을 때 7개 생선에 대한 확률을 구해보기

회귀인가? 분류인가?

우선 최근접 이웃을 사용한다면 샘플 주위 표본을 집어서 확률을 구할 수 있음.


```python
import pandas as pd
fish = pd.read_csv('https://bit.ly/fish_csv_data')
fish.head()
```





  <div id="df-8a65f607-51cc-4a88-a5a2-2a921aa268af" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Species</th>
      <th>Weight</th>
      <th>Length</th>
      <th>Diagonal</th>
      <th>Height</th>
      <th>Width</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Bream</td>
      <td>242.0</td>
      <td>25.4</td>
      <td>30.0</td>
      <td>11.5200</td>
      <td>4.0200</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Bream</td>
      <td>290.0</td>
      <td>26.3</td>
      <td>31.2</td>
      <td>12.4800</td>
      <td>4.3056</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Bream</td>
      <td>340.0</td>
      <td>26.5</td>
      <td>31.1</td>
      <td>12.3778</td>
      <td>4.6961</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Bream</td>
      <td>363.0</td>
      <td>29.0</td>
      <td>33.5</td>
      <td>12.7300</td>
      <td>4.4555</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Bream</td>
      <td>430.0</td>
      <td>29.0</td>
      <td>34.0</td>
      <td>12.4440</td>
      <td>5.1340</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-8a65f607-51cc-4a88-a5a2-2a921aa268af')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-8a65f607-51cc-4a88-a5a2-2a921aa268af button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-8a65f607-51cc-4a88-a5a2-2a921aa268af');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-4b9d8671-4642-470b-a4e0-01cc24981f49">
  <button class="colab-df-quickchart" onclick="quickchart('df-4b9d8671-4642-470b-a4e0-01cc24981f49')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-4b9d8671-4642-470b-a4e0-01cc24981f49 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

    </div>
  </div>




데이터표는 준비되었으니 생선의 종류를 뽑아내서 확인해보자.


```python
print(pd.unique(fish['Species']))
```

    ['Bream' 'Roach' 'Whitefish' 'Parkki' 'Perch' 'Pike' 'Smelt']
    

총 7종류의 생선이 데이터셋에 저장되어 있는걸 확인 할 수 있다.

생선 종류의 확률을 구할 것이기에 종류를 타깃으로 만들고 나머지 5개의 특성을 입력 데이터로 사용해보자.


```python
import numpy
fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']].to_numpy()
```

5개의 특성을 인풋으로 넣었으니 확인해보자.


```python
print(fish_input[:5]) #슬라이싱 사용, 5개까지 출력
```

    [[242.      25.4     30.      11.52     4.02  ]
     [290.      26.3     31.2     12.48     4.3056]
     [340.      26.5     31.1     12.3778   4.6961]
     [363.      29.      33.5     12.73     4.4555]
     [430.      29.      34.      12.444    5.134 ]]
    


```python
fish_target = fish['Species'].to_numpy() # 종류 값을 타겟 데이터로 지정
```


```python
from sklearn.model_selection import train_test_split # 훈련세트 도구
train_input, test_input, train_target, test_target = train_test_split(fish_input, fish_target, random_state=42)
```

데이터를 두 종류로 나누었으니 각 데이터 세트를 표준화 전처리 할 것

StandardScaler 클래스를 사용


```python
from sklearn.preprocessing import StandardScaler
ss = StandardScaler() # ss라는 변수를 스케일러 클래스로 지정
ss.fit(train_input)   # 평균과 표준편차를 계산
train_scaled = ss.transform(train_input)  # 훈련세트 표준화 전처리
test_scaled = ss.transform(test_input)    # 테스트 세트를 표준화 전처리
```

여기까지 데이터 준비는 완료

## <h3>k-최근접 이웃 분류기의 확률 예측</h3>

2장을 참조하여 KNeighborsClassifier 클래스 객체를 만들고

훈련세트를 모델로 훈련, 훈련 세트와 테스트 세트의 점수를 확인하겠다

최근접 이웃 개수는 3개로 지정한다.


```python
from sklearn.neighbors import KNeighborsClassifier
kn = KNeighborsClassifier(n_neighbors=3) # 주변 이웃 개수 지정
kn.fit(train_scaled, train_target)    # 훈련세트 모델 훈련
print(kn.score(train_scaled, train_target)) # 훈련세트 점수
print(kn.score(test_scaled, test_target))   # 테스트세트 점수
```

    0.8907563025210085
    0.85
    

이번 훈련세트와 테스트 세트의 타깃 데이터는 각각 7종류의 생선 종류가 들어가 있다.

이렇게 타깃 데이터에 2개 이상의 클래스가 포함된 문제를 다중 분류라고 부른다.



우리가 2장에서 분류를 할 때는 도미와 빙어를 1과 0으로 분류했었다.

이번 데이터는 7종류의 생선이니 타깃값을 여러개 두어야 할 것이다.

숫자로 둘 수도 있겠으나, 사이킷런에서는 문자열로 된 타깃값을 그대로 사용할 수 있다.

이 타깃값은 classes_ 속성에 포함되어 있다. 확인해보자.


```python
print(kn.classes_)
```

    ['Bream' 'Parkki' 'Perch' 'Pike' 'Roach' 'Smelt' 'Whitefish']
    

첫번째가 bream, 두번째 클래스가 parkki에 해당한다. predict 메서드로 타깃값을 예측해보자.

 테스트 세트에 있는 5개의 샘플이 무엇일지 입력해보자


```python
print(kn.predict(test_scaled[:5]))
```

    ['Perch' 'Smelt' 'Pike' 'Perch' 'Perch']
    


```python
import numpy as np
proba = kn.predict_proba(test_scaled[:5]) # 테스트 세트에 클래스별 확률값
print(np.round(proba, decimals=4))    #위의 확률 값을 소수점 아래 자릿수 지정하여 출력
```

    [[0.     0.     1.     0.     0.     0.     0.    ]
     [0.     0.     0.     0.     0.     1.     0.    ]
     [0.     0.     0.     1.     0.     0.     0.    ]
     [0.     0.     0.6667 0.     0.3333 0.     0.    ]
     [0.     0.     0.6667 0.     0.3333 0.     0.    ]]
    

proba의 출력 순서는 classes_와 같다.

고로 첫번째 열이 bream, 이후 parkki가 뒤따라 온다.

예로 4번째 행의 3열인 0.6667은 4번째 샘플이 Perch가 될 확률을 의미한다.

이 확률이 최근접 이웃 클래스와 동일한지 확인해보자.


```python
distances, indexes = kn.kneighbors(test_scaled[3:4])
print(train_target[indexes])
```

    [['Roach' 'Perch' 'Perch']]
    

실제 4번째 샘플에는 perch가 두 개, roach가 한개이니 1/3과 2/3로 확률 값이 동일한 것을 확인할 수 있다.

하지만 최근접 이웃의 개수로 3개를 지정했으니 나올 수 있는 확률은 1/3 2/3 뿐이다.

클래스는 7개인데 말이다.
이 부분을 해결해보자.



# 로지스틱 회귀

로지스틱 회귀는 회귀이나, 분류 모델이다.

학습 방식은 선형 회귀와 동일하다.

y= ax+b

y = ax^2 + bx + c

위 내용이 기억이 난다면 좋다. 이번에 쓰일 로지스틱 회귀의 학습 방식은

z = ax + by + cv + dg + er + f 같은 형식이다.

a, b, c ,d ,e 는 가중치 혹은 계수를 의미한다. 그 뒤에 붙는 각각의 변수는 특성을 나타낸다(길이, 높이, 무게, 넓이 등등)

여기서 z는 확률이 되기 위해선 0~1 사이의 수가 되어야 한다.

z가 아주 큰 음수여도 0이 되게끔, 아주 큰 양수 일 때도 1이 되게끔 z의 값을 한정시킨다면 위 공식이 성립될 것이다.

이 때 필요한 것이 **시그모이드 함수** 이다.(**로지스틱 함수**)

<image src='https://drive.google.com/uc?id=1FRlATU0UsZSBbhTresF3ziVp8-6_GaTP' />

다음과 같은 공식을 이용한다면 그래프에서도 볼 수 있듯이 아무리 z의 값이 커지거나 작아지더라도 0과 1사이의 값 밖에 나오지 못한다.

넘파이를 사용한 그래프로 좀 더 시각화 해보자.


```python
import numpy as np
import matplotlib.pyplot as plt
z = np.arange(-5, 5, 0.1) # -5와 5 사이에 0.1 간격으로 배열 z를 만들기
phi = 1 / (1+np.exp(-z))  # 로지스틱 함수
plt.plot(z, phi)
plt.xlabel('z')
plt.ylabel('phi')
plt.show()
```


    
![/assets/images/2024-08-22-Machine4-1_36_0.png](</assets/images2024-08-22-Machine4-1_36_0.png>)            
    


그래프를 통해 정말로 0과 1사이의 값으로만 출력되는 걸 확인하였다.

이제 그러면 모델을 훈련하기 전 간단하게 이진 분류를 수행해보도록 하자.

0.5 보다 크다면 양성, 작다면 음성을 기준으로 하고 클래스는 도미와 빙어로만 사용하자.

## 로지스틱 회귀로 이진 분류 수행하기

우리의 훈련세트에는 현재 7 종류의 생선 속성이 존재한다.

이 중 도미와 빙어만을 골라내기 위해 각각 '도미', '빙어'로 인덱싱을 해주어서

넘파이 배열에 도미와 빙어만을 'True'값으로 나머지는 'False' 값으로 설정한다면

손쉽게 도미와 빙어만을 골라낼 수 있을 것이다. 이를 **'불리언 인덱싱'** 라고 한다.


```python
bream_smelt_indexes = (train_target == 'Bream') | (train_target == 'Smelt')    # 변수 지정, 훈련 타겟이 도미이거나 빙어라면 (OR 연산자 활용)
train_bream_smel t = train_scaled[bream_smelt_indexes]                           # 훈련 도미 빙어 입력데이터 = 도미와 빙어의 인덱싱한 것만을 넣는다
target_bream_smelt = train_target[bream_smelt_indexes]                          # 타겟 도미 빙어 = 도미와 빙어의 정답 데이터를 인덱싱한 것만을 넣는다.
```

데이터가 준비되었으니 LogisticRegression 클래스로 모델을 훈련해보자


```python
from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()
lr.fit(train_bream_smelt, target_bream_smelt)   # 위 데이터를 훈련
print(lr.predict(train_bream_smelt[:5]))  # 위 데이터의 처음 5개 샘플의 예측 값을 출력하라
```

    ['Bream' 'Smelt' 'Bream' 'Bream' 'Bream']
    

5개 중 4개가 도미로 예측되었다.

아까처럼 proba 메서드로 확률을 출력해보자.


```python
print(lr.predict_proba(train_bream_smelt[:5]))
```

    [[0.99759855 0.00240145]
     [0.02735183 0.97264817]
     [0.99486072 0.00513928]
     [0.98584202 0.01415798]
     [0.99767269 0.00232731]]
    

1열이 도미, 2열이 빙어에 해당한다. 이진 분류가 잘 수행된 모습이다.

위 데이터를 통해 앞선 로지스틱 회귀 모델이 학습한 계수를 보면 학습한 방정식을 유추할 수 있다.


```python
print(lr.coef_, lr.intercept_)
```

    [[-0.4037798  -0.57620209 -0.66280298 -1.01290277 -0.73168947]] [-2.16155132]
    

<image src= 'https://drive.google.com/uc?id=1cGiqrs2Ovft9IaVt6zP60J0LmvP5Gb-6'/>

방정식을 구했으니 이걸로 z값을 계산하면 확률을 알 수 있을 것이다!

z값의 계산은 decison_function()메서드로 가능하다.


```python
decisions = lr.decision_function(train_bream_smelt[:5])   # 5개까지만
print(decisions)
```

    [-6.02927744  3.57123907 -5.26568906 -4.24321775 -6.0607117 ]
    

이제 이 z 값을 시그모이드 함수에 그대로 대입하면 확률이 나온다.

scipy 라이브러리에는 시그모이드 함수가 존재한다.

expit()를 사용하여 decisions의 배열 값을 확률로 변환해보자


```python
from scipy.special import expit
print(expit(decisions))
```

    [0.00240145 0.97264817 0.00513928 0.01415798 0.00232731]
    

WOW~~ 출력된 값이 아까 도미 빙어 데이터를 proba로 구한 확률과 동일한 값을 보이고 있다.

## 로지스틱 회귀로 다중 분류 수행하기

우리가 사용한 LogisticRegression은 모델을 훈련시키면 기본적으로 100번의 반복을 통해 훈련하는데, 준비한 데이터셋을 사용하면 반복횟수가 부족하다는 경고가 발생한다.

그렇기에 반복 횟수를 1,000으로 설정

그리고 규제를 제어하는 C의 기본값은 1이나, 3장에서 적용한 alpha 규제와는 달리 작을수록 규제가 커진다.

그러므로 큰 규제를 조금 완화하기 위해 20으로 늘리도록 하겠다.


```python
lr = LogisticRegression(C=20, max_iter = 1000)    # 규제는 20으로 완화, 반복 횟수를 1000으로 설정
lr.fit(train_scaled, train_target)    # 훈련세트를 훈련
print(lr.score(train_scaled, train_target))
print(lr.score(test_scaled, test_target))
```

    0.9327731092436975
    0.925
    

훈련세트 테스트 세트 모두 점수가 높고 과대적합이나 과소적합도 보이지 않음.

이대로 처음 5개 샘플에 대한 예측 확률을 출력해보도록 한다


```python
print(lr.predict(test_input[:5]))
```

    ['Perch' 'Pike' 'Perch' 'Perch' 'Perch']
    


```python
proba = lr.predict_proba(test_scaled[:5])
print(np.round(proba, decimals = 3))
```

    [[0.    0.014 0.841 0.    0.136 0.007 0.003]
     [0.    0.003 0.044 0.    0.007 0.946 0.   ]
     [0.    0.    0.034 0.935 0.015 0.016 0.   ]
     [0.011 0.034 0.306 0.007 0.567 0.    0.076]
     [0.    0.    0.904 0.002 0.089 0.002 0.001]]
    

각 7개의 생선 종류가 샘플별로 나타날 수 있는 확률을 출력할 수 있다!


