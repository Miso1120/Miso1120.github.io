---
layout: single
title: "머신러닝2-1"
categories: Machine Learning
sidebar:
    nav: "counts"
---

# 훈련세트와 테스트 세트


머신러닝 알고리즘은 크게 1)지도학습 2)비지도 학습으로 나뉜다.

지도학습은 간단하게 말해 역사와도 같다.

기존에 주어진 데이터를 보고 학습을 하여 미래의 데이터를 예측하기 때문이다.

데이터를 학습시키면, 연관성이나 패턴을 찾기 위해 컴퓨터가 공식을 만드는데 이를 '모델'이라 한다.

그렇다면 잘 만들어진 모델을 얻기 위해선? 데이터가 많을수록 좋을 것이다!

지도학습에서 데이터 = 입력(input)
          정답 = 타깃(target)

즉, 입력물과 입력물이 정답인지 판단한 내용을 합쳐 '훈련 데이터'라고 한다.

이 훈련 데이터를 '훈련 세트'와 '테스트 세트'로 나누어서 데이터를 분류할 것이다.

나뉜 데이터를 각각 평가했을 때 각 세트의 값이 일치한다면 정확한 평가가 이루어진 것!

우선 각 생선들의 길이와 무게를 합쳐서 리스트로 짠다.


```python
fish_length = [25.4, 26.3,26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7,
31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5,
34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0,36.0, 36.0, 37.0,
38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2,
 12.4, 13.0, 14.3, 15.0]
```


```python
fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0,
 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0,
 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0,
700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0,
925.0, 975.0, 950.0, 6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4,
12.2, 19.7, 19.9]
```

짜 놓은 리스트를 2차원 리스트로 변환 (zip 함수)

> 인용구 추가




```python
fish_data = [[l, w] for l, w in zip(fish_length, fish_weight)]
fish_target = [1]*35 + [0]*14
```


```python
print(fish_target)
```

    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
    

이제 데이타와 타겟을 묶어서 도미와 빙어를 분류해줄 클래스를 쓸 것이다. (kn)


```python
from sklearn.neighbors import KNeighborsClassifier
kn = KNeighborsClassifier()
```

클래스로 구분하기전에 리스트를 '훈련세트'와 '테스트 세트'로 나눠야겠죠?

총 49개 중에 몇개만 일부 지정해야하니, 데이터를 효과적으로 구별해서 분리하기 위해 index를 지정할 것이다.

index는 책의 페이지를 알려주는 색인, 목차 같이 리스트를 나타내주는 지표라 보면 된다.

예를 들어 총 49개의 생선 데이터 중 index[4]는 실제로는 리스트 중 5번째인[29.0, 430.0]이 나올 것이다!

리스트 5번째인 [29.0, 430.0]에게 4번이란 이름을 주는 것, 그게 index의 역할이다.


```python
print(fish_data[4])
```

    [29.0, 430.0]
    

그리고 슬라이싱(:)을 사용하면 갯수별 선택이 가능하다.


```python
print(fish_data[0:5])
```

    [[25.4, 242.0], [26.3, 290.0], [26.5, 340.0], [29.0, 363.0], [29.0, 430.0]]
    

하지만 잘 생각을 해보면? fish_data는 그저 35마리의 도미와 14마리의 빙어를 순차적으로 나열한 리스트에 불과하다.

그런데 훈련세트와 테스트 세트로 데이터를 나눌거라면 적어도 두 세트에 도미와 빙어가 골고루 있어야 할 것이다.

그러니 세트를 뽑을 때 어느 정도 데이터를 섞어서 나눠야 할 필요가 있다.

# 넘파이
데이터를 섞어서 쓰기 위한 간편한 툴이 바로 넘파이다!

넘파이는 리스트의 고차원 배열이 가능하다.


```python
import numpy as np
```


```python
input_arr = np.array(fish_data)
target_arr = np.array(fish_target)
```


```python
print(input_arr)
```

    [[  25.4  242. ]
     [  26.3  290. ]
     [  26.5  340. ]
     [  29.   363. ]
     [  29.   430. ]
     [  29.7  450. ]
     [  29.7  500. ]
     [  30.   390. ]
     [  30.   450. ]
     [  30.7  500. ]
     [  31.   475. ]
     [  31.   500. ]
     [  31.5  500. ]
     [  32.   340. ]
     [  32.   600. ]
     [  32.   600. ]
     [  33.   700. ]
     [  33.   700. ]
     [  33.5  610. ]
     [  33.5  650. ]
     [  34.   575. ]
     [  34.   685. ]
     [  34.5  620. ]
     [  35.   680. ]
     [  35.   700. ]
     [  35.   725. ]
     [  35.   720. ]
     [  36.   714. ]
     [  36.   850. ]
     [  37.  1000. ]
     [  38.5  920. ]
     [  38.5  955. ]
     [  39.5  925. ]
     [  41.   975. ]
     [  41.   950. ]
     [   9.8    6.7]
     [  10.5    7.5]
     [  10.6    7. ]
     [  11.     9.7]
     [  11.2    9.8]
     [  11.3    8.7]
     [  11.8   10. ]
     [  11.8    9.9]
     [  12.     9.8]
     [  12.2   12.2]
     [  12.4   13.4]
     [  13.    12.2]
     [  14.3   19.7]
     [  15.    19.9]]
    

이미 49개의 데이터가 2개의 특성(길이, 무게)로 나뉜 것을 알고 있지만, 리스트가 길어 배열 크기를 알고 싶다면 shape 속성을 사용하면 된다.


```python
print(input_arr.shape)
```

    (49, 2)
    

이제 리스트를 재정비했으니 섞을 일만 남았다!

그러나, 입력데이터(fish_data)와 정답데이터(fish_target)의 리스트 배치가 현재 순서대로 나열된 상태인데 입력데이터와 정답데이터가 서로 묶이지 않은 채로 랜덤으로 섞인다면 정답률이 엉망이 될 것이다.

그렇기에 index가 필요한 것! index로 각 리스트를 묶은 다음에 랜덤으로 섞는다면 올바르게 묶인 샘플들이 각 훈련 세트와 테스트 세트로 나뉠 것이다.

인덱스를 주는 방법은 arange()함수를 사용해서 숫자를 정돈하면 된다.


```python
np.random.seed(42)
```


```python
index = np.arange(49)
```


```python
print(index)
```

    [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
     24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
     48]
    


```python
np.random.shuffle(index)
```


```python
print(index)
```

    [29 39 47 42  7 10 24 20 12 13 46 11 38 21 16 17 30  1 34 36  9 33 43 48
      3  6 22 18 19 35  4 28 41  5 23 27 14 44 37 40  8  2 25 26 32 15 45  0
     31]
    

아까 리스트에서 슬라이싱(:)을 쓰면 순차적으로 리스트를 뽑아낼 수 있었다.

넘파이는 그 외에 배열 인덱싱(array indexing)을 사용한다면 여러개의 원하는 순번의 원소만을 뽑아낼 수 있다.


```python
print(input_arr[[1,3]])
```

    [[ 26.3 290. ]
     [ 29.  363. ]]
    


```python
print(index[[0,48]])
```

    [29 31]
    

자 이제 랜덤하게 섞어서 훈련 세트와 테스트 세트로 나누어주면 되겠죠?

저는 책과 다르게 49개의 데이터를 대략 반반으로 나눌겁니다.


```python
train_input = input_arr[index[0:24]]
train_target = target_arr[index[0:24]]
```


```python
test_input = input_arr[index[24:]]
test_target = target_arr[index[24:]]
```

섞인 인덱스의 첫번째 값(input_arr의 원소값)이랑 train input의 첫번째 원소가 일치해야 제대로 된 것이다.


```python
print(input_arr[29], train_input[0])
```

    [  37. 1000.] [  37. 1000.]
    

이제 산점도로 나타내기 위해 멧플롯을 다시 써주도록 한다.

하단의[ :0], [:1]
0 -> length에 관한 것
1 -> weight에 관한 것


```python
import matplotlib.pyplot as plt
plt.scatter(train_input[:,0], train_input[:,1], color='red')
plt.scatter(test_input[:,0], test_input[:,1], color='blue')
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```


    
![png](2024-08-18-Machine2-1_files/2024-08-18-Machine2-1_40_0.png)
    


# 실시 및 평가

kn을 이용해서 최종 훈련 및 테스트를 진행할 것


```python
kn = kn.fit(train_input, train_target)
```


```python
kn.score(test_input, test_target)
```




    1.0




```python
kn.predict(test_input)
```




    array([1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,
           1, 1, 0])




```python
test_target
```




    array([1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,
           1, 1, 0])


