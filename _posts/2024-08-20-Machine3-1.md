---
layout: single
title: "머신러닝3-1(최근접 이웃 회귀)"
categories: MachineLearning
sidebar:
    nav: "counts"
---
# K-최근접 이웃회귀

농어를 무게 단위로 책정하여 팔 것임.

기존의 판매는 마리당 판매였으니 잡은 생선이 농어인지 O X만 판단하면 되는 문제.

무게 단위 판매를 한다면 농어에 대한 무게를 일일히 재야하는 번거로움이 생김.

농어의 무게를 어느정도 예측할 수 있다면?

생선은 당연히 길이가 길수록, 높이가 클수록, 두께가 두꺼울수록 몸무게가 많이 나갈 것이다.

위 변수 사이의 상관관계를 분석하는 것이 이번 문제의 과제 '회귀'라 한다.

# 데이터 준비


```python
import numpy as np
```


```python
perch_length = np.array(
                        [ 8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0,
                         21.0, 21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5,
                          22.5, 22.7, 23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5,
                          27.3, 27.5, 27.5, 27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0,
                          36.5, 36.0, 37.0, 37.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0,
                          40.0, 42.0, 43.0, 43.0, 43.5, 44.0]
                        )

```


```python
perch_weight = np.array(
                        [ 5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0,
                         110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0,
                          130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0,
                          197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0,
                          514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0,
                          820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0,
                          1000.0, 1000.0]
)
```

맷플롭 산점도 활용할건데, 구하고자 하는 값, 즉 정답 값이 무게이므로 타깃 데이터 축인 Y축에 weight에 넣는다.


```python
import matplotlib.pyplot as plt
plt.scatter(perch_length, perch_weight)
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```


    
![/assets/images/2024-08-20-Machine3-1_7_0.png](</assets/images/2024-08-20-Machine3-1_7_0.png>)        


역시나 길이가 커질수록 무게가 늘어나는 결과를 보여줌

자 이제 농어 데이터를 잘 분류하기 위해 우선 검증에 필요한 훈련 세트와 테스트 세트를 만들 것.

저번 시간에 활용한 split 함수를 사용할 것임.



```python
from sklearn.model_selection import train_test_split
train_input, test_input, train_target, test_target = train_test_split(perch_length, perch_weight, random_state=42)
```

근데 아직 2차원 배열로 정리를 안 해준 상태이기에 2차원 배열도 덩달아 해줌


```python
print(test_input.shape)
print(train_input.shape)
```

    (14,)
    (42,)
    

test_input과 train_input의 크기가 각 14, 42임을 확인

2차원 배열로 하려면 (14,1), (42,1) 이런식으로 바꿔주면 되지만,

매번 데이터 크기를 파악 후 reshape 해주는 것보다 자동 정렬 기능을 사용하면 편함 -> (-1, 1)을 넣으면 알아서 자동 정렬해줌.


```python
train_input = train_input.reshape(-1, 1)
test_input = test_input.reshape(-1, 1)
print(train_input.shape, test_input.shape)
```

    (42, 1) (14, 1)
    

# 결정계수 (R²)

분류에선 KNeighborsClassifier를 사용했다면

회귀에선 KNeighborsRegressor을 사용할거임.


```python
from sklearn.neighbors import KNeighborsRegressor

knr = KNeighborsRegressor()
knr.fit(train_input, train_target)

print(knr.score(test_input, test_target))
```

    0.992809406101064
    

훈련해서 점수를 매긴 이 점수를 결정계수  (R²)라고 부른다.

분류에서의 정확도와 비슷한 개념이다. 분류는 기다 아니다를 구분하는거라면

회귀에서 결정계수는 내가 이 모델을 얼마나 신뢰할 수 있는지에 대한 수치이다.


```python
print(knr.score(train_input, train_target))
```

    0.9698823289099254
    


```python

```

훈련세트를 훈련시키고 테스트 세트에 스코어를 매긴 점수는 0.99인데

훈련세트를 훈련시키고 훈련 세트에 스코어를 매긴 점수는 0.96 가량임

둘이 비슷하지가 않음.

## 과대적합 vs 과소적합

훈련세트와 테스트 세트의 점수가 상이함.

우리가 훈련 시킨건 훈련 세트이기 때문에 보통 훈련세트에 더 높은 점수가 나와야 하는데 반대의 결과가 나왔음.

이를 '과소적합'이라 한다.

훈련세트를 훈련한 기준으로, (훈련 < 테스트) or (훈련 and 테스트 << 예측점수 보다 심하게 낮은 경우)

이를 과소적합이라 하며, 반대로

훈련세트 >>> 테스트 점수 처럼 테스트 점수가 굉장히 나쁘다면 '과대적합' 이라 한다.

'과소적합'과 '과대적합'을 해결하기 위해선 KNeighborsRegressor의 이웃 값에 변동을 주어야 한다.

과소적합의 경우 모델을 더욱 복잡하게 만들어야하므로 이웃값을 줄임으로써 패턴에 민감하게 만든다.

과대적합일 경우 모델을 덜 복잡하게 만들어야하므로 이웃값을 늘림으로써 패턴에 둔감하게 만든다.


```python
knr.n_neighbors = 3
knr.fit(train_input, train_target)
print(knr.score(train_input, train_target))
print(knr.score(test_input, test_target))
```

    0.9804899950518966
    0.9746459963987609
    

# 연습 문제


```python
knr = KNeighborsRegressor()
```


```python
x = np.arange(5, 45).reshape(-1, 1)
```


```python
for n in [1, 5, 10]:
  knr.n_neighbors = n
  knr.fit(train_input, train_target)
  prediction = knr.predict(x)
  plt.scatter(train_input, train_target)
  plt.plot(x, prediction)
  plt.title('n_neighbors = {}'.format(n))
  plt.xlabel('length')
  plt.ylabel('weight')
  plt.show()
```


    
![/assets/images/2024-08-20-Machine3-1_29_0.png](</assets/images/2024-08-20-Machine3-1_29_0.png>)        
    



    
![/assets/images/2024-08-20-Machine3-1_29_1.png](</assets/images/2024-08-20-Machine3-1_29_1.png>)        

    



    
![/assets/images/2024-08-20-Machine3-1_29_2.png](</assets/images/2024-08-20-Machine3-1_29_2.png)        

    

